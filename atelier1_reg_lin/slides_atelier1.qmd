---
title: "Atelier 1 ‚Äî R√©gression lin√©aire multiple"
format:
  revealjs:
    toc: false
include-after-body: ../utils/return-site.html
---

```{r echo=FALSE}
source("../utils/requirements.R")
library(AmesHousing)
library(GGally)
library(scales)
theme_set(ggplot2::theme_minimal())
```

# Plan 

- Brise-glace ‚Äî *Pourquoi plusieurs variables ?*
- Rappel r√©gression simple ‚Üí multiple
- Th√©orie compl√®te ‚Äî √©criture matricielle, hypoth√®ses, variables cat√©gorielles, standardisation
- Diagnostics essentiels
- **Mission 1** ‚Äî Mod√®le sur `AmesHousing::ames`
- Tests & incertitude ‚Äî tests t/F, intervalles, calibration, biais-variance
- **Mission 2** ‚Äî Tester & interpr√©ter
- Compl√©ments ‚Äî s√©lection de variables, transformations, influence
- D√©brief & pi√®ges fr√©quents

---

## Brise-glace 

- Visualisation rapide : surface vs prix (nuage de points)
- Brainstorm : *Quelles autres variables ajouter ?*
- Prix de vente ~ aire habitable

```{r}
ames <- AmesHousing::make_ames()
ames %>%
 ggplot(aes(Gr_Liv_Area, Sale_Price)) +
 geom_point(alpha=.3) +
 labs(x="Aire habitable (pi¬≤)", y="Prix de vente ($)" )+ 
 scale_y_continuous(labels = dollar_format(prefix = "$", big.mark = ","))
```

---

## Rappel : r√©gression simple ‚Üí multiple 

::: incremental
- Objectif : approximer une relation moyenne entre une r√©ponse $Y$ et des pr√©dicteurs $X$.
- Extension √† $p$ pr√©dicteurs : tenir compte simultan√©ment de plusieurs effets.
:::

::: {.fragment}
$$
Y = \beta_0 + \beta_1 x_1 + \cdots + \beta_p x_p + \varepsilon,\qquad \mathbb{E}[\varepsilon]=0,\ \operatorname{Var}(\varepsilon)=\sigma^2
$$
:::

- **Id√©e cl√©** : chaque $\beta_j$ mesure l‚Äôeffet de $x_j$ *toutes choses √©gales par ailleurs*.

---

## √âcriture matricielle 

Soit $\mathbf{y}\in\mathbb{R}^n$, $\mathbf{X}\in\mathbb{R}^{n\times (p+1)}$ (avec colonne d‚Äô1), $\boldsymbol{\beta}\in\mathbb{R}^{p+1}$.

$$
\mathbf{y} = \mathbf{X}\boldsymbol{\beta} + \boldsymbol{\varepsilon}, \quad \widehat{\boldsymbol{\beta}}_{\text{OLS}} = (\mathbf{X}^\top \mathbf{X})^{-1}\mathbf{X}^\top \mathbf{y}
$$

- **Projection g√©om√©trique** : $\widehat{\mathbf{y}}$ est la projection orthogonale de $\mathbf{y}$ sur l‚Äôespace colonnes de $\mathbf{X}$.
- **R√©sidus** : $\widehat{\boldsymbol{\varepsilon}} = \mathbf{y} - \mathbf{X}\widehat{\boldsymbol{\beta}}$, somme nulle, orthogonaux aux colonnes de $\mathbf{X}$.

---

## Hypoth√®ses & cons√©quences 

- **Lin√©arit√©** : la relation moyenne est lin√©aire.
- **Ind√©pendance** des erreurs.
- **Homosc√©dasticit√©** : $\operatorname{Var}(\varepsilon_i)=\sigma^2$.
- **Normalit√©** des erreurs (utile pour IC/tests).
- **Pas de colin√©arit√© parfaite** : $\mathbf{X}^\top \mathbf{X}$ inversible.

Cons√©quences :
- Estimateurs non biais√©s $\mathbb{E}[\widehat{\beta}]=\beta$.
- Estimateur de $\sigma^2$: $\widehat{\sigma}^2 = \frac{1}{n-p-1}\sum \widehat{\varepsilon}_i^2$.
- Variance des coefficients : diag$(\widehat{\sigma}^2 (\mathbf{X}^\top \mathbf{X})^{-1})$.

---

## Encodage des variables cat√©gorielles 

::: incremental
- Facteur √† $K$ niveaux ‚áí $K-1$ indicatrices.
- Choix du **niveau de r√©f√©rence** = base de comparaison.
- Interactions : $x \times \text{facteur}$ pour des pentes diff√©rentes.
:::

::: {.fragment}
```{r}
d <- ames %>%
  select(Sale_Price, Gr_Liv_Area, Overall_Qual, Neighborhood) %>%
  mutate(Neighborhood = droplevels(Neighborhood))
m_cat <- lm(Sale_Price ~ Gr_Liv_Area + Overall_Qual + Neighborhood, data = d)
tidy(m_cat) %>% slice(1:8)
```
:::

---

## Standardisation des variables
- Utile pour comparer l‚Äôimportance relative des pr√©dicteurs.
- Les coefficients sont exprim√©s en √©cart-types.

```{r}
mod_std <- lm(scale(Sale_Price) ~ scale(Gr_Liv_Area) + scale(as.numeric(Overall_Qual)) + scale(Year_Built), data=ames)
broom::tidy(mod_std)
```

---

## Diagnostics essentiels 

- **R√©sidus vs valeurs ajust√©es** : v√©rifier lin√©arit√© & homog√©n√©it√©.
- **QQ-plot** : v√©rifier normalit√©.
- **Leverage & influence** : points qui ¬´ tirent ¬ª le mod√®le (distance de Cook, seuil 4/n).
- **Multicolin√©arit√©** : VIF (Variance Inflation Factor).

```{r}
m0 <- lm(Sale_Price ~ Gr_Liv_Area + Overall_Qual + Year_Built + Full_Bath + Garage_Cars, data=ames)
par(mfrow=c(2,2)); plot(m0); par(mfrow=c(1,1))
car::vif(m0)
plot(cooks.distance(m0), type="h", main="Distance de Cook")
abline(h=4/nrow(ames), col="red", lty=2)
```

---

## üöÄ Transition ‚Äî Mission 1

**Objectifs de Mission 1 :**

- Explorer rapidement les donn√©es (EDA).

- Construire un mod√®le multiple (‚â§ 6 pr√©dicteurs).

- V√©rifier les diagnostics (r√©sidus, normalit√©, homosc√©dasticit√©, VIF).

- Interpr√©ter les coefficients bruts et standardis√©s.

---

## Mission 1 ‚Äî Construire le mod√®le sur Ames
Ouvrir **`missions/M1_ames.qmd`** ‚Äî EDA ‚Üí `lm()` ‚Üí diagnostics ‚Üí interpr√©tation.

---

## Tests d‚Äôhypoth√®ses (Mission 2)
- **Test individuel** : $H_0: \beta_j = 0$ vs $H_1: \beta_j \neq 0$ (t, p-value).
- **Test global** : $H_0: \beta_1=\cdots=\beta_p=0$ (F).
- **Mod√®les embo√Æt√©s** : comparaison via ANOVA.

```{r}
sum_mod <- summary(m0)
sum_mod$coefficients
anova(lm(Sale_Price ~ Gr_Liv_Area + Overall_Qual + Year_Built, data=ames), m0)
```

---

## Intervalles de confiance vs pr√©diction
- **IC** : incertitude sur la **moyenne conditionnelle** $E[Y|X]$.
- **IP** : incertitude sur une **nouvelle observation**.
- IP toujours plus large que IC.

```{r}
newd <- data.frame(Gr_Liv_Area=2000, Overall_Qual="Very_Poor", Year_Built=2000, Full_Bath=2, Garage_Cars=2)
predict(m0, newd, interval="confidence")
predict(m0, newd, interval="prediction")
```

---

## Calibration et couverture des IP
- IP95 ‚âà 95% de couverture si le mod√®le est bien sp√©cifi√©.
- V√©rification empirique possible sur √©chantillon test.

```{r}
set.seed(42)
idx <- sample(seq_len(nrow(ames)), size = floor(.8*nrow(ames)))
train <- ames[idx,]; test <- ames[-idx,]
mod_train <- lm(Sale_Price ~ Gr_Liv_Area + Overall_Qual + Year_Built, data=train)
pred_pi <- predict(mod_train, newdata=test, interval="prediction")
mean(test$Sale_Price >= pred_pi[,"lwr"] & test$Sale_Price <= pred_pi[,"upr"])
```

---

## Compromis biais-variance
- Mod√®le trop simple : biais √©lev√©.
- Mod√®le trop complexe : variance √©lev√©e.
- Objectif : √©quilibre pour minimiser l‚Äôerreur test.

```{r echo=FALSE}
curve((x-2)^2/5 + 1/x, from=1, to=6, ylim=c(0,6), xlab="Complexit√© du mod√®le", ylab="Erreur test", col="blue", lwd=2)
```

---

## üöÄ Transition ‚Äî Mission 2

**Objectifs de Mission 2 :**

- Comparer mod√®les simple vs complet.

- √âvaluer performance pr√©dictive (RMSE/MAE).

- Tester les coefficients et comparer via ANOVA.

- Construire et interpr√©ter IC et IP.

- V√©rifier calibration et couverture.

---

## Mission 2  ‚Äî Tester & interpr√©ter
Ouvrir **`missions/M2_interpretation.qmd`** ‚Äî Train/Test ‚Üí RMSE/MAE ‚Üí tests ‚Üí intervalles ‚Üí calibration.

---

## S√©lection & complexit√© 
- Crit√®res d‚Äôinformation : **AIC**/**BIC** (intuition : √©quilibre ajustement/complexit√©).
- `step()` : exploration mais √† manier avec recul.
- Pr√©f√©rer une s√©lection raisonn√©e, guid√©e par le domaine.

```{r}
m_small <- lm(Sale_Price ~ Gr_Liv_Area + Overall_Qual + Year_Built, data=ames)
AIC(m0, m_small)
```

---

## Transformations & non-lin√©arit√©s 
- Transformation de $Y$ (log) pour variance non constante.
- Transformation de $X$ (log, racine) ou **termes quadratiques**.

```{r}
m_log <- lm(log(Sale_Price) ~ log(Gr_Liv_Area) + Overall_Qual + Year_Built, data=ames)
broom::glance(m_log)
```

---

## Influence & points atypiques 
- Leverage √©lev√© + grand r√©sidu ‚áí potentiellement influents.
- Toujours v√©rifier la **qualit√© des donn√©es** avant exclusion.

---

## D√©brief & pi√®ges fr√©quents 
- Colin√©arit√© ignor√©e ‚áí coefficients instables.
- Facteurs mal encod√©s ‚áí interpr√©tations erron√©es.
- Sur-ajustement ‚áí validation indispensable.
- Confusion entre $R^2$ et **performance pr√©dictive**.

---

## Quiz interactif (rapide)

- **Vrai/Faux** : Ajouter une variable cat√©gorielle cr√©e autant de colonnes que de niveaux.  
<details><summary>R√©ponse</summary>Faux ‚Äî on cr√©e $K-1$ indicatrices si le facteur poss√®de $K$ niveaux (r√©f√©rence incluse implicitement).</details>

- **Question** : Pourquoi un $R^2$ plus grand ne garantit-il pas une meilleure **pr√©diction** ?  
<details><summary>R√©ponse</summary>Un mod√®le peut sur-ajuster l‚Äô√©chantillon d‚Äôentra√Ænement. Il faut juger sur un √©chantillon test (RMSE/MAE) et non sur l‚Äôajustement seul.</details>
